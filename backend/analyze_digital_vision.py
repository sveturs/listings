#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∞ Digital Vision –ø—Ä–∞–π—Å–∞

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç XML –ø—Ä–∞–π—Å Digital Vision –∏ –≤—ã–¥–∞–µ—Ç:
- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–π
- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞—Ç—Ä–∏–±—É—Ç–æ–≤
- –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

Usage:
    python3 analyze_digital_vision.py --file DigitalVision.xml --output analysis.json
"""

import argparse
import json
import re
import xml.etree.ElementTree as ET
from collections import defaultdict, Counter
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Set, Optional
from pathlib import Path


@dataclass
class CategoryStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
    total: int = 0
    level1: Set[str] = field(default_factory=set)
    level2: Set[str] = field(default_factory=set)
    level3: Set[str] = field(default_factory=set)
    category_product_count: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    top_categories: List[Dict[str, any]] = field(default_factory=list)


@dataclass
class AttributeStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞—Ç—Ä–∏–±—É—Ç–∞–º"""
    detected: List[str] = field(default_factory=list)
    unique_values: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))
    value_counts: Dict[str, Dict[str, int]] = field(default_factory=lambda: defaultdict(lambda: defaultdict(int)))


@dataclass
class VariantGroup:
    """–ì—Ä—É–ø–ø–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤"""
    base_name: str
    products: List[Dict[str, str]]
    variant_count: int
    variant_attributes: Set[str]
    confidence: float


@dataclass
class ImageStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    total_products_with_images: int = 0
    total_images: int = 0
    avg_images_per_product: float = 0.0
    max_images_per_product: int = 0
    percentage: float = 0.0


@dataclass
class AnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    total_products: int
    categories: Dict
    attributes: Dict
    variants: Dict
    images: Dict


class DigitalVisionAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä Digital Vision –ø—Ä–∞–π—Å–∞"""

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    COLOR_PATTERNS = [
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Ü–≤–µ—Ç–∞ (–∞–Ω–≥–ª–∏–π—Å–∫–∏–π, —Å–µ—Ä–±—Å–∫–∏–π)
        r'\b(crn[ai]|bel[ai]|crven[ai]?|zelen[ai]?|plav[ai]|pink|black|white|red|blue|green|yellow|grey|gray|silver|gold)\b',
        # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Ü–≤–µ—Ç–∞ + —Ü–≤–µ—Ç (dark blue, light yellow)
        r'\b(dark|light|bright|deep)\s+(blue|red|green|yellow|black|white|grey|gray)\b',
        # –û–¥–∏–Ω–æ—á–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Ü–≤–µ—Ç–∞
        r'\b(light|dark|bright|deep)\b',
    ]

    SIZE_PATTERNS = [
        r'\b\d+\/\d+\/\d+\/\d+\s*mm\b',  # 42/44/45/49mm - —á–µ—Ç—ã—Ä–µ —Ä–∞–∑–º–µ—Ä–∞
        r'\b\d+\/\d+\/\d+\s*mm\b',  # 38/40/41mm - —Ç—Ä–∏ —Ä–∞–∑–º–µ—Ä–∞
        r'\b\d+\/\d+\s*mm\b',  # 42/44mm - –¥–≤–∞ —Ä–∞–∑–º–µ—Ä–∞
        r'\/\d+mm\b',  # /49mm - –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —á–∞—Å—Ç–∏ –ø–æ—Å–ª–µ —Å–ª—ç—à–∞
        r'\b\d+mm\b',  # 40mm - –æ–¥–∏–Ω–æ—á–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
        r'\b[SML]\/[ML]\b',  # S/M, M/L
        r'\b(small|medium|large|xs|s|m|l|xl|xxl)\b',
    ]

    MODEL_PATTERNS = [
        # –ú–æ–¥–µ–ª–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ - –ø–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω!
        r'\bSamsung\s+Galaxy\s+[A-Z]\d+\+?\b',  # Samsung Galaxy S21 - –ø–æ–ª–Ω–∞—è —Ñ–æ—Ä–º–∞ —Å–Ω–∞—á–∞–ª–∞
        r'\bGalaxy\s+[A-Z]\d+\+?\b',  # Galaxy S21
        r'\biPhone\s+\d+\s*(Pro|Plus|Max|Mini)?\b',  # iPhone 12, iPhone 13 Pro
        r'\b(Samsung|Apple|Xiaomi|Huawei)\b',  # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
        # –û–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –º–æ–¥–µ–ª–µ–π
        r'\b\d{2,4}[A-Z]+\b',  # 2021G, KB-UM-104
    ]

    def __init__(self, xml_file: str):
        self.xml_file = xml_file
        self.tree = None
        self.root = None

    def load_xml(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å XML —Ñ–∞–π–ª"""
        try:
            self.tree = ET.parse(self.xml_file)
            self.root = self.tree.getroot()
            return True
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ XML: {e}")
            return False

    def analyze_categories(self) -> CategoryStats:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        stats = CategoryStats()

        if self.root is None:
            return stats

        for product in self.root.findall('artikal'):
            kat1 = product.findtext('kategorija1', '')
            kat2 = product.findtext('kategorija2', '')
            kat3 = product.findtext('kategorija3', '')

            # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            if kat1:
                stats.level1.add(kat1)
                stats.category_product_count[kat1] += 1

            if kat2:
                full_kat2 = f"{kat1} > {kat2}" if kat1 else kat2
                stats.level2.add(full_kat2)
                stats.category_product_count[full_kat2] += 1

            if kat3:
                full_kat3 = f"{kat1} > {kat2} > {kat3}" if kat1 and kat2 else kat3
                stats.level3.add(full_kat3)
                stats.category_product_count[full_kat3] += 1
                stats.total += 1

        # –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–æ–≤–∞—Ä–æ–≤
        stats.top_categories = [
            {"category": cat, "product_count": count}
            for cat, count in sorted(stats.category_product_count.items(), key=lambda x: x[1], reverse=True)[:20]
        ]

        return stats

    def analyze_attributes(self) -> AttributeStats:
        """–ê–Ω–∞–ª–∏–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤"""
        stats = AttributeStats()

        # –ê—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        attr_fields = [
            'uvoznik', 'godinaUvoza', 'zemljaPorekla',
            'dostupan', 'naAkciji', 'barKod'
        ]

        if self.root is None:
            return stats

        for product in self.root.findall('artikal'):
            for attr in attr_fields:
                value = product.findtext(attr, '').strip()
                if value:
                    stats.unique_values[attr].add(value)
                    stats.value_counts[attr][value] += 1

        stats.detected = attr_fields

        return stats

    def extract_variant_attributes(self, product_name: str) -> Dict[str, Optional[str]]:
        """–ò–∑–≤–ª–µ—á—å –∞—Ç—Ä–∏–±—É—Ç—ã –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"""
        attributes = {}

        # –¶–≤–µ—Ç
        for pattern in self.COLOR_PATTERNS:
            match = re.search(pattern, product_name, re.IGNORECASE)
            if match:
                attributes['color'] = match.group(0)
                break

        # –†–∞–∑–º–µ—Ä
        for pattern in self.SIZE_PATTERNS:
            match = re.search(pattern, product_name, re.IGNORECASE)
            if match:
                attributes['size'] = match.group(0)
                break

        # –ú–æ–¥–µ–ª—å
        for pattern in self.MODEL_PATTERNS:
            match = re.search(pattern, product_name, re.IGNORECASE)
            if match:
                attributes['model'] = match.group(0)
                break

        return attributes

    def extract_base_name(self, product_name: str) -> str:
        """–ò–∑–≤–ª–µ—á—å –±–∞–∑–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –±–µ–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤"""
        name = product_name

        # –£–±–∏—Ä–∞–µ–º —Ü–≤–µ—Ç–∞
        for pattern in self.COLOR_PATTERNS:
            name = re.sub(pattern, '', name, flags=re.IGNORECASE)

        # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã
        for pattern in self.SIZE_PATTERNS:
            name = re.sub(pattern, '', name, flags=re.IGNORECASE)

        # –£–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª–∏
        for pattern in self.MODEL_PATTERNS:
            name = re.sub(pattern, '', name, flags=re.IGNORECASE)

        # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤
        name = re.sub(r'\s+', ' ', name).strip()

        return name

    def detect_variants(self, min_group_size: int = 2, min_confidence: float = 0.7) -> List[VariantGroup]:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤"""
        groups = defaultdict(list)

        if self.root is None:
            return []

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –±–∞–∑–æ–≤–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é
        for product in self.root.findall('artikal'):
            name = product.findtext('naziv', '').strip()
            if not name:
                continue

            base_name = self.extract_base_name(name)
            variant_attrs = self.extract_variant_attributes(name)

            # –¢–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã —Å –≤–∞—Ä–∏–∞–Ω—Ç–Ω—ã–º–∏ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
            if variant_attrs:
                groups[base_name].append({
                    'name': name,
                    'sku': product.findtext('sifra', ''),
                    'attributes': variant_attrs
                })

        # –§–∏–ª—å—Ç—Ä—É–µ–º –≥—Ä—É–ø–ø—ã
        variant_groups = []
        for base_name, products in groups.items():
            if len(products) < min_group_size:
                continue

            # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
            all_attrs = set()
            for p in products:
                all_attrs.update(p['attributes'].keys())

            # Confidence: –ø—Ä–æ—Ü–µ–Ω—Ç —Ç–æ–≤–∞—Ä–æ–≤ —Å –≤–∞—Ä–∏–∞–Ω—Ç–Ω—ã–º–∏ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
            confidence = len(products) / max(len(products), 1)

            if confidence >= min_confidence:
                variant_groups.append(VariantGroup(
                    base_name=base_name,
                    products=products,
                    variant_count=len(products),
                    variant_attributes=all_attrs,
                    confidence=confidence
                ))

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        variant_groups.sort(key=lambda x: x.variant_count, reverse=True)

        return variant_groups

    def analyze_images(self) -> ImageStats:
        """–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        stats = ImageStats()

        if self.root is None:
            return stats

        total_products = len(self.root.findall('artikal'))
        image_counts = []

        for product in self.root.findall('artikal'):
            slike = product.find('slike')
            if slike is not None:
                images = slike.findall('slika')
                if images:
                    stats.total_products_with_images += 1
                    image_count = len(images)
                    stats.total_images += image_count
                    image_counts.append(image_count)

        if image_counts:
            stats.avg_images_per_product = sum(image_counts) / len(image_counts)
            stats.max_images_per_product = max(image_counts)

        if total_products > 0:
            stats.percentage = (stats.total_products_with_images / total_products) * 100

        return stats

    def analyze(self) -> AnalysisResult:
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∞–π—Å–∞"""
        if not self.load_xml():
            return None

        total_products = len(self.root.findall('artikal'))

        print(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é {total_products} —Ç–æ–≤–∞—Ä–æ–≤...")

        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
        print("  üè∑Ô∏è  –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
        category_stats = self.analyze_categories()

        # –ê—Ç—Ä–∏–±—É—Ç—ã
        print("  üîß –ê–Ω–∞–ª–∏–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤...")
        attribute_stats = self.analyze_attributes()

        # –í–∞—Ä–∏–∞–Ω—Ç—ã
        print("  üé® –î–µ—Ç–µ–∫—Ü–∏—è –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤...")
        variant_groups = self.detect_variants()

        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        print("  üì∏ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
        image_stats = self.analyze_images()

        return AnalysisResult(
            total_products=total_products,
            categories={
                "total": category_stats.total,
                "level1": len(category_stats.level1),
                "level2": len(category_stats.level2),
                "level3": len(category_stats.level3),
                "unique_level1": sorted(list(category_stats.level1)),
                "unique_level2": sorted(list(category_stats.level2))[:50],  # Top 50
                "unique_level3": sorted(list(category_stats.level3))[:100],  # Top 100
                "top_categories": category_stats.top_categories
            },
            attributes={
                "detected": attribute_stats.detected,
                "unique_values": {
                    k: sorted(list(v))[:50]  # Top 50 values per attribute
                    for k, v in attribute_stats.unique_values.items()
                },
                "value_distribution": {
                    k: sorted(v.items(), key=lambda x: x[1], reverse=True)[:20]
                    for k, v in attribute_stats.value_counts.items()
                }
            },
            variants={
                "potential_groups": len(variant_groups),
                "products_affected": sum(g.variant_count for g in variant_groups),
                "top_variant_groups": [
                    {
                        "base_name": g.base_name,
                        "variant_count": g.variant_count,
                        "attributes": list(g.variant_attributes),
                        "confidence": g.confidence,
                        "examples": g.products[:5]  # Top 5 examples
                    }
                    for g in variant_groups[:20]  # Top 20 groups
                ]
            },
            images={
                "total_products_with_images": image_stats.total_products_with_images,
                "total_images": image_stats.total_images,
                "avg_images_per_product": round(image_stats.avg_images_per_product, 2),
                "max_images_per_product": image_stats.max_images_per_product,
                "percentage": round(image_stats.percentage, 1)
            }
        )


def main():
    parser = argparse.ArgumentParser(description='Analyze Digital Vision XML price list')
    parser.add_argument('--file', required=True, help='Path to Digital Vision XML file')
    parser.add_argument('--output', required=True, help='Output JSON file path')
    parser.add_argument('--min-variants', type=int, default=2, help='Minimum variants in group (default: 2)')
    parser.add_argument('--confidence', type=float, default=0.7, help='Minimum confidence (default: 0.7)')

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞
    if not Path(args.file).exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.file}")
        return 1

    print(f"üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ Digital Vision –ø—Ä–∞–π—Å–∞")
    print(f"üìÅ –§–∞–π–ª: {args.file}")
    print()

    # –ê–Ω–∞–ª–∏–∑
    analyzer = DigitalVisionAnalyzer(args.file)
    result = analyzer.analyze()

    if result is None:
        print("‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
        return 1

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_data = asdict(result)
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    print()
    print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {args.output}")
    print()
    print("üìä –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  üì¶ –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {result.total_products}")
    print(f"  üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏–π (level 1/2/3): {result.categories['level1']}/{result.categories['level2']}/{result.categories['level3']}")
    print(f"  üé® –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –≥—Ä—É–ø–ø –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {result.variants['potential_groups']}")
    print(f"  üì∏ –¢–æ–≤–∞—Ä–æ–≤ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏: {result.images['total_products_with_images']} ({result.images['percentage']}%)")
    print()

    return 0


if __name__ == '__main__':
    exit(main())
