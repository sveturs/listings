#!/usr/bin/env python3
"""
Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¾Ğ²
ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ğ¸Ñ… Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¾Ğ²
"""

import re
import os
from pathlib import Path
from typing import Dict, List, Set

def analyze_component_translations(project_root: str) -> Dict:
    """ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¾Ğ² Ğ² ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ°Ñ…"""
    
    src_dir = Path(project_root) / 'frontend/svetu/src'
    
    # Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ñ useTranslations - Ğ±ĞµÑ€ĞµĞ¼ Ğ¸Ğ· Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
    components_with_translations = [
        'components/Header.tsx',
        'app/[locale]/create-listing/CreateListingClient.tsx', 
        'components/marketplace/HomePage.tsx',
        'components/AuthButton.tsx',
        'components/search/CategorySelector.tsx',
        'components/cart/ShoppingCartModal.tsx',
        'components/Chat/ChatWindow.tsx',
        'app/[locale]/admin/layout-client.tsx',
        'components/storefronts/create/steps/BasicInfoStep.tsx',
        'components/GIS/LocationPicker.tsx'
    ]
    
    analysis = {
        'components_analyzed': [],
        'translation_patterns': {},
        'potential_issues': [],
        'namespace_usage': {}
    }
    
    namespace_counter = {}
    
    for component_path in components_with_translations:
        full_path = src_dir / component_path
        
        if not full_path.exists():
            analysis['potential_issues'].append({
                'type': 'file_not_found',
                'file': component_path,
                'severity': 'low'
            })
            continue
            
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            component_analysis = analyze_single_component(content, component_path)
            analysis['components_analyzed'].append(component_analysis)
            
            # Ğ¡Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ namespace
            for namespace in component_analysis['namespaces']:
                namespace_counter[namespace] = namespace_counter.get(namespace, 0) + 1
                
        except Exception as e:
            analysis['potential_issues'].append({
                'type': 'analysis_error',
                'file': component_path,
                'error': str(e),
                'severity': 'medium'
            })
    
    analysis['namespace_usage'] = dict(sorted(namespace_counter.items(), key=lambda x: x[1], reverse=True))
    
    return analysis

def analyze_single_component(content: str, file_path: str) -> Dict:
    """ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ°"""
    
    # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
    use_translations_pattern = re.compile(r"useTranslations\(['\"]([^'\"]+)['\"]\)")
    translation_calls_pattern = re.compile(r"(?:^|\s)t\(['\"]([^'\"]+)['\"]")
    const_t_pattern = re.compile(r"const\s+(\w+)\s*=\s*useTranslations\(['\"]([^'\"]+)['\"]\)")
    
    analysis = {
        'file': file_path,
        'namespaces': [],
        'translation_calls': [],
        'const_names': [],
        'potential_issues': []
    }
    
    # Ğ˜Ñ‰ĞµĞ¼ useTranslations
    for match in use_translations_pattern.finditer(content):
        namespace = match.group(1)
        analysis['namespaces'].append(namespace)
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ° Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸
        if '.' in namespace:
            analysis['potential_issues'].append({
                'type': 'nested_namespace',
                'namespace': namespace,
                'line': content[:match.start()].count('\n') + 1
            })
    
    # Ğ˜Ñ‰ĞµĞ¼ ĞºĞ¾Ğ½ÑÑ‚Ğ°Ğ½Ñ‚Ñ‹ Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ°Ğ¼Ğ¸ 
    for match in const_t_pattern.finditer(content):
        const_name = match.group(1)
        namespace = match.group(2)
        analysis['const_names'].append({'name': const_name, 'namespace': namespace})
    
    # Ğ˜Ñ‰ĞµĞ¼ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñ‹ t()
    translation_calls = []
    for match in translation_calls_pattern.finditer(content):
        key = match.group(1)
        line = content[:match.start()].count('\n') + 1
        translation_calls.append({'key': key, 'line': line})
    
    analysis['translation_calls'] = translation_calls[:20]  # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ²Ñ‹Ğ²Ğ¾Ğ´
    
    return analysis

def main():
    project_root = '/data/hostel-booking-system'
    
    print("ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ¾Ñ‡Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ°Ğ¼Ğ¸...")
    
    analysis = analyze_component_translations(project_root)
    
    print(f"\nğŸ“Š Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« ĞĞĞĞ›Ğ˜Ğ—Ğ ĞšĞĞœĞŸĞĞĞ•ĞĞ¢ĞĞ’:")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"ğŸ“ ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²: {len(analysis['components_analyzed'])}")
    print(f"âš ï¸  ĞŸĞ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼: {len(analysis['potential_issues'])}")
    print()
    
    # Ğ¢Ğ¾Ğ¿ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ñ… namespace
    print("ğŸ·ï¸  Ğ¢ĞĞŸ-10 Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—Ğ£Ğ•ĞœĞ«Ğ¥ NAMESPACE:")
    for i, (namespace, count) in enumerate(list(analysis['namespace_usage'].items())[:10], 1):
        print(f"   {i:2}. {namespace:<20} ({count} Ñ€Ğ°Ğ·)")
    print()
    
    # Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ°
    print("ğŸ” Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞ«Ğ™ ĞĞĞĞ›Ğ˜Ğ— ĞšĞĞœĞŸĞĞĞ•ĞĞ¢ĞĞ’:")
    for comp in analysis['components_analyzed'][:10]:  # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 10
        print(f"\nğŸ“„ {comp['file']}")
        print(f"   Namespace: {', '.join(comp['namespaces']) if comp['namespaces'] else 'ĞĞ•Ğ¢'}")
        print(f"   Ğ’Ñ‹Ğ·Ğ¾Ğ²Ñ‹ t(): {len(comp['translation_calls'])}")
        
        if comp['potential_issues']:
            print(f"   âš ï¸  ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹: {len(comp['potential_issues'])}")
            for issue in comp['potential_issues']:
                print(f"      - {issue['type']}: {issue.get('namespace', 'N/A')}")
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
    output_file = Path(project_root) / 'spec-kit/translation-audit/reports/component_analysis.txt'
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("ĞĞĞĞ›Ğ˜Ğ— Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞ˜Ğ¯ ĞŸĞ•Ğ Ğ•Ğ’ĞĞ”ĞĞ’ Ğ’ ĞšĞĞœĞŸĞĞĞ•ĞĞ¢ĞĞ¥\n")
        f.write("=" * 50 + "\n\n")
        
        f.write(f"ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²: {len(analysis['components_analyzed'])}\n")
        f.write(f"ĞŸĞ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼: {len(analysis['potential_issues'])}\n\n")
        
        f.write("Ğ¢ĞĞŸ Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—Ğ£Ğ•ĞœĞ«Ğ¥ NAMESPACE:\n")
        for namespace, count in analysis['namespace_usage'].items():
            f.write(f"  {namespace}: {count}\n")
        f.write("\n")
        
        f.write("Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞ«Ğ™ ĞĞĞĞ›Ğ˜Ğ— ĞšĞĞœĞŸĞĞĞ•ĞĞ¢ĞĞ’:\n")
        for comp in analysis['components_analyzed']:
            f.write(f"\nĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚: {comp['file']}\n")
            f.write(f"  Namespace: {', '.join(comp['namespaces'])}\n")
            f.write(f"  Ğ’Ñ‹Ğ·Ğ¾Ğ²Ñ‹ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¾Ğ²: {len(comp['translation_calls'])}\n")
            if comp['potential_issues']:
                f.write(f"  ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹: {comp['potential_issues']}\n")
    
    print(f"\nâœ… Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² {output_file}")

if __name__ == '__main__':
    main()